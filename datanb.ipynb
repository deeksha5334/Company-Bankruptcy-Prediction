{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "'seaborn-whitegrid' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/CleaningML/.venv/lib/python3.9/site-packages/matplotlib/style/core.py:137\u001b[0m, in \u001b[0;36muse\u001b[0;34m(style)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     style \u001b[38;5;241m=\u001b[39m \u001b[43m_rc_params_in_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Desktop/CleaningML/.venv/lib/python3.9/site-packages/matplotlib/__init__.py:873\u001b[0m, in \u001b[0;36m_rc_params_in_file\u001b[0;34m(fname, transform, fail_on_error)\u001b[0m\n\u001b[1;32m    872\u001b[0m rc_temp \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 873\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_or_url(fname) \u001b[38;5;28;01mas\u001b[39;00m fd:\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py:117\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/CleaningML/.venv/lib/python3.9/site-packages/matplotlib/__init__.py:850\u001b[0m, in \u001b[0;36m_open_file_or_url\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m    849\u001b[0m fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(fname)\n\u001b[0;32m--> 850\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    851\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'seaborn-whitegrid'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Set plotting style\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstyle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseaborn-whitegrid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m sns\u001b[38;5;241m.\u001b[39mset_palette(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSet2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# 1. Download and Load the Dataset\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# If you're using Kaggle API\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# !kaggle datasets download -d fedesoriano/company-bankruptcy-prediction\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Replace 'path/to/data.csv' with your actual file path\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/CleaningML/.venv/lib/python3.9/site-packages/matplotlib/style/core.py:139\u001b[0m, in \u001b[0;36muse\u001b[0;34m(style)\u001b[0m\n\u001b[1;32m    137\u001b[0m         style \u001b[38;5;241m=\u001b[39m _rc_params_in_file(style)\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    140\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstyle\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m is not a valid package style, path of style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile, URL of style file, or library style name (library \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyles are listed in `style.available`)\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    143\u001b[0m filtered \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m style:  \u001b[38;5;66;03m# don't trigger RcParams.__getitem__('backend')\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: 'seaborn-whitegrid' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)"
     ]
    }
   ],
   "source": [
    "# Taiwan Bankruptcy Dataset - Exploration Notebook\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "# 1. Download and Load the Dataset\n",
    "# If you're using Kaggle API\n",
    "# !kaggle datasets download -d fedesoriano/company-bankruptcy-prediction\n",
    "# If you're using KaggleHub (as in your screenshot)\n",
    "# import kagglehub\n",
    "# path = kagglehub.dataset_download(\"fedesoriano/company-bankruptcy-prediction\")\n",
    "# print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Load the dataset\n",
    "# Replace 'path/to/data.csv' with your actual file path\n",
    "df = pd.read_csv('data/bankruptcy_data.csv')\n",
    "\n",
    "# 2. Basic Dataset Exploration\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check data types and missing values\n",
    "print(\"\\nData Information:\")\n",
    "print(df.info())\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(df['Bankrupt?'].value_counts())\n",
    "print(df['Bankrupt?'].value_counts(normalize=True).map(lambda x: f\"{x:.2%}\"))\n",
    "\n",
    "# 3. Visualize Class Imbalance\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.countplot(x='Bankrupt?', data=df)\n",
    "plt.title('Distribution of Bankruptcy Cases', fontsize=16)\n",
    "plt.xlabel('Bankrupt (1) vs Non-Bankrupt (0)', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "\n",
    "# Add count labels\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha = 'center', va = 'bottom', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Check for Missing Values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"\\nMissing Values:\")\n",
    "print(missing_values[missing_values > 0] if any(missing_values > 0) else \"No missing values found.\")\n",
    "\n",
    "# 5. Feature Analysis\n",
    "# Calculate correlation with target variable\n",
    "correlation_with_target = df.corrwith(df['Bankrupt?']).sort_values(ascending=False)\n",
    "\n",
    "# Get top 10 features (excluding the target itself)\n",
    "top_10_positive = correlation_with_target[1:11]\n",
    "top_10_negative = correlation_with_target[-10:].iloc[::-1]\n",
    "\n",
    "# Print top correlated features\n",
    "print(\"\\nTop 10 Positively Correlated Features:\")\n",
    "print(top_10_positive)\n",
    "print(\"\\nTop 10 Negatively Correlated Features:\")\n",
    "print(top_10_negative)\n",
    "\n",
    "# Visualize top correlations\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.subplot(2, 1, 1)\n",
    "top_10_positive.plot(kind='bar')\n",
    "plt.title('Top 10 Positively Correlated Features with Bankruptcy', fontsize=16)\n",
    "plt.ylabel('Correlation Coefficient', fontsize=14)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "top_10_negative.plot(kind='bar')\n",
    "plt.title('Top 10 Negatively Correlated Features with Bankruptcy', fontsize=16)\n",
    "plt.ylabel('Correlation Coefficient', fontsize=14)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Distribution of Top Features by Bankruptcy Status\n",
    "# Select top features (both positive and negative correlations)\n",
    "top_features = list(top_10_positive.index) + list(top_10_negative.index)\n",
    "top_features = top_features[:10]  # Select first 10 for visualization\n",
    "\n",
    "# Create box plots for each feature by bankruptcy status\n",
    "plt.figure(figsize=(15, 20))\n",
    "for i, feature in enumerate(top_features, 1):\n",
    "    plt.subplot(5, 2, i)\n",
    "    sns.boxplot(x='Bankrupt?', y=feature, data=df)\n",
    "    plt.title(f'Distribution of {feature}', fontsize=12)\n",
    "    plt.xlabel('Bankruptcy Status (1=Bankrupt, 0=Non-Bankrupt)', fontsize=10)\n",
    "    plt.ylabel(feature, fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7. Correlation Matrix Heatmap\n",
    "# Select top 15 features correlated with bankruptcy\n",
    "correlation_abs = correlation_with_target.abs().sort_values(ascending=False)\n",
    "top_features = list(correlation_abs[1:16].index)\n",
    "top_features.append('Bankrupt?')  # Add the target variable\n",
    "\n",
    "# Create correlation matrix for top features\n",
    "correlation_matrix = df[top_features].corr()\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "mask = np.triu(correlation_matrix)\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, mask=mask)\n",
    "plt.title('Correlation Matrix of Top 15 Features', fontsize=16)\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 8. Feature Distributions and Outliers\n",
    "plt.figure(figsize=(20, 15))\n",
    "for i, feature in enumerate(top_features[:9], 1):  # First 9 features\n",
    "    plt.subplot(3, 3, i)\n",
    "    sns.histplot(data=df, x=feature, hue='Bankrupt?', kde=True, bins=30)\n",
    "    plt.title(f'Distribution of {feature}', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check for outliers in top features\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.boxplot(data=df[top_features])\n",
    "plt.title('Boxplot of Top Features', fontsize=16)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9. Data Preparation for Modeling\n",
    "# Split data into features and target\n",
    "X = df.drop('Bankrupt?', axis=1)\n",
    "y = df['Bankrupt?']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n",
    "print(\"Class distribution in training set:\")\n",
    "print(y_train.value_counts(normalize=True).map(lambda x: f\"{x:.2%}\"))\n",
    "\n",
    "# 10. Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 11. Handle Class Imbalance with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Resampled training set shape:\", X_train_resampled.shape, y_train_resampled.shape)\n",
    "print(\"Class distribution after SMOTE:\")\n",
    "print(pd.Series(y_train_resampled).value_counts(normalize=True).map(lambda x: f\"{x:.2%}\"))\n",
    "\n",
    "# 12. Model Training and Evaluation\n",
    "# This section provides a basic framework for model training\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Performance metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    \n",
    "    print(f\"--- {model_name} Performance ---\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"ROC AUC: {auc:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f'Confusion Matrix - {model_name}', fontsize=14)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title(f'ROC Curve - {model_name}', fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return model, accuracy, auc\n",
    "\n",
    "# Train Logistic Regression\n",
    "lr_model = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "lr_model, lr_acc, lr_auc = evaluate_model(lr_model, X_train_resampled, y_train_resampled, \n",
    "                                        X_test_scaled, y_test, \"Logistic Regression\")\n",
    "\n",
    "# Train Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "rf_model, rf_acc, rf_auc = evaluate_model(rf_model, X_train_resampled, y_train_resampled, \n",
    "                                        X_test_scaled, y_test, \"Random Forest\")\n",
    "\n",
    "# Train XGBoost\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    scale_pos_weight=len(y_train[y_train==0])/len(y_train[y_train==1]),\n",
    "    learning_rate=0.1, \n",
    "    n_estimators=100, \n",
    "    max_depth=4,\n",
    "    random_state=42\n",
    ")\n",
    "xgb_model, xgb_acc, xgb_auc = evaluate_model(xgb_model, X_train_resampled, y_train_resampled, \n",
    "                                          X_test_scaled, y_test, \"XGBoost\")\n",
    "\n",
    "# 13. Compare Model Performance\n",
    "models = ['Logistic Regression', 'Random Forest', 'XGBoost']\n",
    "accuracies = [lr_acc, rf_acc, xgb_acc]\n",
    "aucs = [lr_auc, rf_auc, xgb_auc]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, accuracies, width, label='Accuracy')\n",
    "plt.bar(x + width/2, aucs, width, label='AUC')\n",
    "\n",
    "plt.ylabel('Score', fontsize=14)\n",
    "plt.title('Model Performance Comparison', fontsize=16)\n",
    "plt.xticks(x, models, fontsize=12)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 14. Feature Importance Analysis\n",
    "# For Random Forest\n",
    "plt.figure(figsize=(12, 8))\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance.head(15))\n",
    "plt.title('Random Forest Feature Importance', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# For XGBoost\n",
    "plt.figure(figsize=(12, 8))\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "sns.barplot(x='importance', y='feature', data=xgb_importance.head(15))\n",
    "plt.title('XGBoost Feature Importance', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 15. Save the Best Model (assuming XGBoost performed best)\n",
    "best_model = xgb_model\n",
    "\n",
    "# Save model and scaler\n",
    "joblib.dump(scaler, 'models/scaler.pkl')\n",
    "\n",
    "# Save the feature names for later use\n",
    "import json\n",
    "feature_names = X.columns.tolist()\n",
    "with open('models/feature_names.json', 'w') as f:\n",
    "    json.dump(feature_names, f)\n",
    "\n",
    "print(\"Model and preprocessing components saved successfully.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
